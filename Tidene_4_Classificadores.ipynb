{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidene Códigos - Classificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recebe os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import sklearn\n",
    "import gensim\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copiei aqui as classes definidas quando foram criados os vetorizadores... ela poderia ser importada do notebook no qual foi definida\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import *    #https://www.nltk.org/api/nltk.tokenize.html\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "        self.tokenizer = nltk.tokenize.RegexpTokenizer(\"[a-zA-Z']+\")\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in self.tokenizer.tokenize(doc) if (len(t)>2)]\n",
    "\n",
    "class StemTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.tokenizer = nltk.tokenize.RegexpTokenizer(\"[a-zA-Z']+\")\n",
    "    def __call__(self, doc):\n",
    "        return [self.stemmer.stem(t) for t in self.tokenizer.tokenize(doc) if (len(t)>2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrega a matriz de features e o vetorizador e a matriz de features \n",
    "tfidf_vectorizer = pickle.load(open(\"tfidf_vectorizer.pickle\", \"rb\"))\n",
    "X_train_tfidf = pickle.load(open(\"X_train_tfidf.pickle\", \"rb\"))\n",
    "\n",
    "X_train_tfidf.shape   # matriz de features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lê os textos e as classes de treinamento - e também as classes do arquivo de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AQUI PODE-SE MUDAR QUAL A CLASSE QUE VAI SER CONSIDERADA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "corpus =  pd.read_csv('data/train_min.csv',encoding='utf8')\n",
    "\n",
    "corpus_train , corpus_test =  train_test_split(corpus, train_size=0.7)\n",
    "\n",
    "train_classes = corpus_train['sentiment'].values.tolist()\n",
    "\n",
    "test_docs = corpus_test['review'].values.tolist()\n",
    "test_classes = corpus_test['sentiment'].values.tolist()\n",
    "\n",
    "\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_docs) #representa os documentos com o padrao treinado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificador Bayesiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf_NB = MultinomialNB().fit(X_train_tfidf, train_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predizendo classes para o texto novo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_NB = clf_NB.predict(X_test_tfidf)\n",
    "print(\"Acurácia: \", np.mean(predicted_NB == test_classes))           \n",
    "\n",
    "print('classe real => classe predita')\n",
    "\n",
    "for real, pred in zip(test_classes, predicted_NB):\n",
    "    print((real,pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(test_classes, predicted_NB,target_names=[\"negative\",\"positive\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confusao\n",
    "print(metrics.confusion_matrix(test_classes, predicted_NB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificadore SGDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf_SGDC = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=None)\n",
    "clf_SGDC.fit(X_train_tfidf, train_classes)\n",
    "predicted_SGDC = clf_SGDC.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Acurácia: \", np.mean(predicted_SGDC == test_classes))           \n",
    "\n",
    "print('classe real => classe predita')\n",
    "\n",
    "for real, pred in zip(test_classes, predicted_SGDC):\n",
    "    print((real,pred))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas de avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(test_classes, predicted_SGDC,target_names=[\"negative\",\"positive\"]))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Matriz de confusão\")\n",
    "print(metrics.confusion_matrix(test_classes, predicted_SGDC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificador SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf_SVC = LinearSVC(random_state=0)\n",
    "clf_SVC.fit(X_train_tfidf, train_classes)\n",
    "predicted_SVC = clf_SVC.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Acurácia: \", np.mean(predicted_SVC == test_classes))           \n",
    "\n",
    "\n",
    "print('classe real => classe predita')\n",
    "\n",
    "for real, pred in zip(test_classes, predicted_SVC):\n",
    "    print((real,pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(test_classes, predicted_SVC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Matriz de confusão\")\n",
    "print(metrics.confusion_matrix(test_classes, predicted_SVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
