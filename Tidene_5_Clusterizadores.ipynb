{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Códigos Tidene - Clusterização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Leitura de dados iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "class readCorpus(object):\n",
    "    def __init__(self,csvfile,list_of_fields_to_read=[],tokenizer=None,encoding='utf8'):\n",
    "        self.csvfile = csvfile\n",
    "        self.fields = list_of_fields_to_read\n",
    "        self.tokenizer = tokenizer\n",
    "        self.encoding = encoding\n",
    "    \n",
    "    def __iter__(self):\n",
    "        f = open(self.csvfile,encoding=self.encoding, errors='ignore')\n",
    "        reader = csv.reader(f, delimiter=',', quoting=csv.QUOTE_MINIMAL) #separador dos campos\\n\",\n",
    "        headers = next(reader, None)\n",
    "        if (len(self.fields) <= 0):\n",
    "            self.fields = headers\n",
    "        selected_field_indexes = []\n",
    "        for idx,field in enumerate(headers):\n",
    "            if field in self.fields:\n",
    "                selected_field_indexes.append(idx)\n",
    "\n",
    "        for line in reader:\n",
    "            if line:\n",
    "                yield [line[idx] for idx in selected_field_indexes] if (len(selected_field_indexes)>1) else (line[selected_field_indexes[0]] if not self.tokenizer else tokenizer.tokenize(line[selected_field_indexes[0]]))\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import *    #https://www.nltk.org/api/nltk.tokenize.html\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "        self.tokenizer = nltk.tokenize.RegexpTokenizer(\"[a-zA-Z']+\")\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in self.tokenizer.tokenize(doc) if (len(t)>2)]\n",
    "\n",
    "class StemTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.tokenizer = nltk.tokenize.RegexpTokenizer(\"[a-zA-Z']+\")\n",
    "    def __call__(self, doc):\n",
    "        \n",
    "        return [self.stemmer.stem(t) for t in self.tokenizer.tokenize(doc) if (len(t)>2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=LemmaTokenizer(), stop_words='english', min_df=1)\n",
    "\n",
    "\n",
    "\n",
    "pd_corpus =  pd.read_csv(\"toy.csv\",encoding='utf8')\n",
    "corpus = pd_corpus['data']\n",
    "classes = pd_corpus['subgroup'].values.tolist()\n",
    "\n",
    "## NOS OUTROS EXEMPLOS ESSAS DUAS ACOES (FIT E TRANSFORM) SAO FEITAS EM UMA SO, ATRAVES DO FIT_TRANSFORM ..\n",
    "##   FIZ A SEPARACAO AQUI PARA PODER GRAVAR NO DISCO O VETORIZADOR E PODER USA-LO PARA VETORIZAR TEXTOS NOVOS DEPOIS\n",
    "tfidf_vectorizer = tfidf_vectorizer.fit(corpus,classes) # treina o vetorizador\n",
    "X_train_tfidf = tfidf_vectorizer.transform(corpus) # transforma os textos em uma matriz sparsa numpy\n",
    "\n",
    "\n",
    "# gravando no disco vetorizador e a matriz vetorizada\n",
    "pickle.dump(tfidf_vectorizer, open(\"tfidf_vectorizer.pickle\", \"wb\"))\n",
    "pickle.dump(X_train_tfidf, open(\"X_train_tfidf.pickle\", \"wb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train_tfidf = pickle.load(open(\"X_train_tfidf.pickle\", \"rb\"))\n",
    "train_classes = pd.read_csv('toy.csv',encoding='utf8')['subgroup'].values.tolist()\n",
    "train_docs = readCorpus(\"toy.csv\",list_of_fields_to_read=['subgroup','othersipcs','data']) #CORPUS ITERATOR\n",
    "\n",
    "\n",
    "#test_docs = readCorpus(\"testtoy.csv\",list_of_fields_to_read=['data'])          # ou pd.read_csv('testtoy.csv',encoding='utf8')['data']     #.values.tolist()\n",
    "#test_classes = pd.read_csv('testtoy.csv',encoding='utf8')['subgroup'].values.tolist()\n",
    "#X_test_tfidf = tfidf_vectorizer.transform(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 27.355\n",
      "Iteration  1, inertia 13.281\n",
      "Iteration  2, inertia 13.069\n",
      "Converged at iteration 2: center shift 0.000000e+00 within tolerance 9.279556e-08\n",
      "Initialization complete\n",
      "Iteration  0, inertia 24.900\n",
      "Iteration  1, inertia 13.069\n",
      "Converged at iteration 1: center shift 0.000000e+00 within tolerance 9.279556e-08\n",
      "Initialization complete\n",
      "Iteration  0, inertia 26.848\n",
      "Iteration  1, inertia 13.906\n",
      "Converged at iteration 1: center shift 0.000000e+00 within tolerance 9.279556e-08\n",
      "Initialization complete\n",
      "Iteration  0, inertia 26.613\n",
      "Iteration  1, inertia 13.838\n",
      "Converged at iteration 1: center shift 0.000000e+00 within tolerance 9.279556e-08\n",
      "Initialization complete\n",
      "Iteration  0, inertia 26.618\n",
      "Iteration  1, inertia 13.482\n",
      "Iteration  2, inertia 13.264\n",
      "Converged at iteration 2: center shift 0.000000e+00 within tolerance 9.279556e-08\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k = 2\n",
    "\n",
    "km = KMeans(n_clusters=k, init='k-means++', max_iter=100, n_init=5, verbose=1)\n",
    "km_vectorizer = km.fit(X_train_tfidf)\n",
    "pickle.dump(km_vectorizer, open(\"km_vectorizer.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(km.labels_,bins=k)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Clusters \n",
      "\n",
      "+++++ Cluster  1  +++++\n",
      "\n",
      "B03B00402   B07B00408   separation apparatus this invention relates to a method for separation of a light material from a heavier material a separation table of vibrator type and a cyclone and a fan means being found the invention also relates to an arrangement for making the separation possible it is previously known by m \n",
      "\n",
      "B03B00500   B01D01102-E02F00388   method and installation for desalinating sand and suction hopper comprising such an installation the invention relates to the desalination of sand extracted from the sea the desalination of sand is a primary precondition if sea sand is to be able to be used on land the requirement imposed is that th \n",
      "\n",
      "B03B00546   B03B01100   device for sorting a mix of objects the invention relates to a device for sorting a mix of objects using a bed of fluidized material comprising a frame a porous bottom for supporting the material to be fluidized during operation means for supplying pressurized air to the porous bottom and two convey \n",
      "\n",
      "B03B00510   B29B01702   method of separating particles in a fluid medium and an apparatus therefor the present invention relates to a method of separating particles in a fluid medium having a density higher than that of the particles to be separated whereby a mixture of the particles to be separated is fed to a separation  \n",
      "\n",
      "B03B00512   B03B00522-B03B00524-B04B00300-B04B01104   hutch chamber for jig background of invention this invention relates to jigs which separate materials in a feed mixture on the basis of differing specific gravities and especially but not exclusively to centrifugal jigs of the general type described in international patent publication nos w086 04269 \n",
      "\n",
      "B03B00562   B01D02100   a method and a device for treatment of medium the present invention relates to a method for the separation of lighter particles from heavier particles in a liquid medium which contains lighter particles and heavier sinking particles which require to be washed in particular sand and in particular at  \n",
      "\n",
      "B03B00562   B01J00820   title a reflux classifier technical field the present invention relates generally to a method or an apparatus for segregating or classifying particles the invention relates particularly though not exclusively to a fluidized multistage lamellae classifier particle fractionator or reflux classifier be \n",
      "\n",
      "B03B00562   B03B00564-B03B00566-B01D02102   particle classifier field of the invention the present invention relates to segregating particles from a suspension and specifically to segregating particles of a certain size or density range from the suspension in which the particle size or density fluctuates the present invention is well suited t \n",
      "\n",
      "B03B00566       apparatus for cleaning and destoning particulate foods field of the invention this invention relates to the cleaning of particulate materials that are slightly heavier than water with a specific gravity 20 20c range of 1 01 to 2 01 and thus readily sink in water by the removal of foreign particulate \n",
      "\n",
      "+++++ Cluster  0  +++++\n",
      "\n",
      "H03F00126       error extraction using autocalibrating rf correlator field of the invention the present invention relates in general to communication systems and is particularly directed to the use of an auto calibrating rf correlator to control an rf distortion extractor so that the rf carrier is canceled leaving  \n",
      "\n",
      "H03F00130       audio transient suppression device 1 field of the invention the present invention relates to audio reproduction and more particularly to suppression of audible transients 2 background of the invention typically a fast transient occurs at the output of an audio amplifier when the output is enabled e  \n",
      "\n",
      "H03F00102   H03F00130   flexible current control in power amplifiers background of invention field of the invention the present invention relates generally to an improvement in amplifier circuitry particularly to improved amplifier circuitry for telecommunications systems and more particularly to circuitry for flexibly con \n",
      "\n",
      "H03M00730   H03M00746   system and method for compressing an audio signal field of the invention the invention relates generally to a system and method for compressing a digital representation of an analog signal and more particularly to a system and method for compressing a digital representation of an audio analog signal \n",
      "\n",
      "H03M00730       system employing data compression transparent mode with compression parameter negotiation this application claims the benefit of u s provisional application seriaxo 60 192 841 filed march 29 2000 and of u s provisional application serial no 60 238 356 filed october 6 2000 the entire contents of whic \n",
      "\n",
      "H03M00740       arithmetic encoding decoding of a multi channel information signal the invention relates to a data compression apparatus for data compressing a plurality of at least two digital information signals the invention also relates to a data compression method to a data expansion apparatus to a transmissio \n",
      "\n",
      "H03M00740       universally programmable variable length decoder the present invention relates generally to variable length decoders vlds used in data transmission systems such as digital video data transmission systems and more particularly to a vld which is programmable for decoding digital video data streams whi \n",
      "\n",
      "H03M00746       reception of variable and run length encoded data field of the invention the invention relates to reception of variable and run length encoded data the variable and run length encoded data may be for example video information which has been encoded in accordance with a moving pictures expert group m \n",
      "\n"
     ]
    }
   ],
   "source": [
    "clusters = {}\n",
    "\n",
    "for idx,(subgroup,othersipcs,data) in enumerate(train_docs):\n",
    "    if km.labels_[idx] in clusters.keys():\n",
    "        clusters[km.labels_[idx]].append([subgroup,othersipcs,data[0:300]]) \n",
    "    else:\n",
    "        clusters[km.labels_[idx]]=[[subgroup,othersipcs,data[0:300]]]\n",
    "    \n",
    "\n",
    "print(\" Clusters \\n\")\n",
    "\n",
    "for k in clusters.keys():\n",
    "    print(\"+++++ Cluster \",k,\" +++++\\n\")\n",
    "    for ipc,othersipcs,text in clusters[k]:\n",
    "        print (ipc,\" \",othersipcs,\" \",text,\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# OPCAO PARA SALVAR EM ARQUIVOS COM O NOME DO CLUSTER, DENTRO DE UMA PASTA CLUSTERS\n",
    "#for idx,(subgroup,data,otherspcis) in enumerate(train_docs):\n",
    "#    arq = \"cluster\" + str(km.labels_[idx])\n",
    " #   with open(\"CLUSTERS/\"+arq, \"a\") as myfile:\n",
    "  #      myfile.write(subgroup+'\\t'+otherspcis+'\\t'+data+'\\n')  # separarado por \\t\n",
    "  #  myfile.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
